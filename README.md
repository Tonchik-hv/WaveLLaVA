# WaveLLaVA: кодирование модальностей в LLM с помощью вейвлет-преобразования, проект [AIRI Summer School](https://airi.net/ru/summer-school-2024/).

## Цель: 
Применить Wavelet преобразования для получения представления изображения в мультимодальных моделях для задачи image captioning

## Задача: 
Построить мультимодальную модель на базе LLaVA с заменой CLIP энкодера, на эмбеддинги полученные после Wavelet преобразования

## Желаемый Результат:

Получить модель которая сможет генерировать описания картинок

# Эксперименты и Результаты
### Версия 0.
Задача: обучить архитектуру для классификации с вейвлет-преобразованием и без него, сравнить точность классификации и вычислительную скорость.

Результат: классификатор, обученный с вейвлет-преобразованием, обучается на 30% быстрее, при этом средняя абсолютная потеря в точности классификации составляет 3.6955%.

### Версия 1.
Переходим к задаче image captioning. В качестве пайплайна используется мультимодальная модель OmniFusion. Мы убрали Vision Encoder. К изображениям применяем Вейвлет-преобразования с уровнем декомпозиции 5. Делаем reshape полученных коэффициентов до единой размерности и конкатенируем по всем каналам. В качестве обучаемого мэппинга используем линейный слой. Датасет LLaVA-ReCap-118К. Модель Qwen2-1.5B.

Результат:

