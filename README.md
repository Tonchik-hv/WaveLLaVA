# WaveLLaVA: кодирование модальностей в LLM с помощью вейвлет-преобразования, проект [AIRI Summer School](https://airi.net/ru/summer-school-2024/).

## Цель: 
Применить Wavelet преобразования для получения представления изображения в мультимодальных моделях для задачи image captioning

## Задача: 
Построить мультимодальную модель на базе LLaVA с заменой CLIP энкодера, на эмбеддинги полученные после Wavelet преобразования

## Желаемый Результат:

Получить модель которая сможет генерировать описания картинок

# Эксперименты и Результаты
### Версия 0.
Задача: обучить архитектуру для классификации с вейвлет-преобразованием и без него, сравнить точность классификации и вычислительную скорость.

Результат: классификатор, обученный с вейвлет-преобразованием, обучается на 30% быстрее, при этом средняя абсолютная потеря в точности классификации составляет 3.6955%.

### Версия 1.
Переходим к задаче image captioning. В качестве пайплайна используется мультимодальная модель OmniFusion. Мы убрали Vision Encoder. К изображениям применяем Вейвлет-преобразования с уровнем декомпозиции 5. Делаем reshape полученных коэффициентов до единой размерности и конкатенируем по всем каналам. В качестве обучаемого мэппинга используем линейный слой. Датасет LLaVA-ReCap-118К. Модель Qwen2-1.5B.

Результат: Модель отвечает связным текстов, но, к сожалению не угадывает правильно, что изображено на картинках.

### Версия 1.2. 
Хотелось поэкспериментировать с моделью. Мы пробовали уменьшать уровень декомпозиции Вейвлет-преобразования. С уменьшением уровня мы добавляли сверточные слои и MaxPool слои, чтобы обучение не падало по памяти. 

Результат: уменьшение уровней и добавление CNN, MaxPool слоев не улучшило качество модели.

### Версия 2. 
Обучить модель на датасете OleehyO/latex-formulas.

Результат: в данной случае видно что предсказанные формулы не соответсвуют входным, а также компилируются с ошибкой в среде LaTeX

### Версия 3.

В данной версии эксперимента запустили языковую модель QWEN-0.5B, которая на вход принимала семантические токены эмбеднигов полученные с помощью вейвлет преобразования. На основе теории из статьи Wavelet-Based Image Tokenizer for Vision Transformers была проведена имплементация метода, который называется Semantic Token Embedding.

Результат: как видно из выхода модели, она генерирует связанный текст, но не описывающий то, что происходит на входном изображении. 

## Выводы
Таким образом, в результате проделанной работы, были обучены модели QWEN-0.5B, QWEN-1.5B, проверенна базовая гипотеза на ResNet18. Получены результаты инференса модели wavelet-to-text и проанализированы ответы модели.

## Будущее планы 
В планах на будущее:
- Решение обратной задачи, то есть по заданному текстовому описанию получить вейвлет преобразованное изображение
- Альтернативные методы работы с семантическими токенами
- Приближение эмбедингов CLIP c помощью вейвлетов
- Рассмотреть text-to-image датасеты



